# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
  beats {
    port => 5044
  }
}

## 配置过滤器
#filter {
#  grok {
#    match => {
#     "message" =>"%{IPORHOST:remote_addr} - - \[%{HTTPDATE:log_timestamp}\] %{HOSTNAME:http_host} %{WORD:request_method} \"%{URIPATH1:uri}\" \"%{URIPARM1:param}\" %{BASE10NUM:http_status} %{BASE10NUM:body_bytes_sent} \"(?:%{URI1:http_referrer}|-)\" (%{BASE10NUM:upstream_status}|-) (?:%{HOSTPORT:upstream_addr}|-) (%{BASE16FLOAT:upstream_response_time}|-) (%{BASE16FLOAT:request_time}|-) (?:%{QUOTEDSTRING:user_agent}|-) \"(%{WORD:x_forword_for}|-)\""
#    }
#  }
#  # beats传递过来的一些附加数据并不是我们想要的，同时把message数据也去掉，只保留我们想要的数据即可
#  mutate {
#    remove_field => ["message","host","log","agent","ecs","input","tags"]
#  }
#  date {
#  	match => [ "log_timestamp", "yyyy-MMM-dd-HH:mm:ss Z" ]
#  	locale => "cn"
#	}
#}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
    #user => "elastic"
    #password => "changeme"
  }
   stdout {
      codec => rubydebug
   }
}